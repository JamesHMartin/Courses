{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconstructing BERT's Vocabulary\n",
    "\n",
    "BERT and BERT-like models almost always have a vocabulary of around 30k words. We'll get to what this really means later in the course. For now, let's just assume it means that the model has a form of meaning associated with each of the 30k entries in the lexicon. Intuitively, this aligns well with our notions of how many words fluent English speakers know.\n",
    "\n",
    "Here we have a list of the words that are in the \"BERT-base\" lower-case model in the file BERT-vocab.txt, with one \"word\" per line.  Let's see what that looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30522 BERT-vocab.txt\n"
     ]
    }
   ],
   "source": [
    "wc -l BERT-vocab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're in the right ballpark with 30522 lines (words). Let's see what's in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD]\n",
      "[unused0]\n",
      "[unused1]\n",
      "[unused2]\n",
      "[unused3]\n",
      "[unused4]\n",
      "[unused5]\n",
      "[unused6]\n",
      "[unused7]\n",
      "[unused8]\n"
     ]
    }
   ],
   "source": [
    "head BERT-vocab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, those don't look like the words we want.  BERT uses a number of unique symbols in its workings, including symbols like [PAD], [CLS], [SEP] and a couple of others.  These aren't really words. And it looks like it reserves some entries ([unused\\*]) for future work (typically for adaptation to specialized domains). These aren't the words we're looking for.  Let's see how many of these there are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD]\n",
      "[unused0]\n",
      "[unused1]\n",
      "[unused2]\n",
      "[unused3]\n",
      "[unused4]\n",
      "[unused5]\n",
      "[unused6]\n",
      "[unused7]\n",
      "[unused8]\n"
     ]
    }
   ],
   "source": [
    "grep '^\\[' < BERT-vocab.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1000\n"
     ]
    }
   ],
   "source": [
    "grep '^\\[' < BERT-vocab.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29522\n"
     ]
    }
   ],
   "source": [
    "grep -v '^\\[' < BERT-vocab.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we're down to 29k. Let's see what else is in there if we skip over the [] items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "\"\n",
      "#\n",
      "$\n",
      "%\n",
      "&\n",
      "'\n",
      "(\n",
      ")\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "grep -v '^\\[' < BERT-vocab.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we said that subword algorithms start with an initial vocabulary of characters. In class we took that to be characters, numbers and punctuation.  That's really not quite right, if you're using arbitrary web docs and things like Wikipedia then you're going to run into a lot of odd characters.  Better to just use all the unicode characters that occur in the training text. Let's see what we get we look at all the single character entries in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "\"\n",
      "#\n",
      "$\n",
      "%\n",
      "&\n",
      "'\n",
      "(\n",
      ")\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "grep '^.$' < BERT-vocab.txt | head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     997\n"
     ]
    }
   ],
   "source": [
    "grep '^.$' < BERT-vocab.txt | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. We' just knocked another 1000 entries from BERT's word list. Down to roughly 28,500. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     997\n"
     ]
    }
   ],
   "source": [
    "grep '^.$' < BERT-vocab.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. That drops us down another 1000 or so to 28k.  \n",
    "\n",
    "Now the wordpiece algorithm used in BERT employs ## to mark the start of the subword units that the algorithm discovers. Let's see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##s\n",
      "##a\n",
      "##e\n",
      "##i\n",
      "##ing\n",
      "##n\n",
      "##o\n",
      "##d\n",
      "##ed\n",
      "##r\n",
      "##y\n",
      "##t\n",
      "##er\n",
      "##ly\n",
      "##l\n",
      "##m\n",
      "##u\n",
      "##es\n",
      "##h\n",
      "##on\n",
      "##k\n",
      "##us\n",
      "##c\n",
      "##g\n",
      "##an\n",
      "##p\n",
      "##en\n",
      "##in\n",
      "##man\n",
      "##al\n",
      "##ia\n",
      "##2\n",
      "##z\n",
      "##is\n",
      "##1\n",
      "##b\n",
      "##3\n",
      "##ra\n",
      "##na\n",
      "##ers\n",
      "##f\n",
      "##4\n",
      "##le\n",
      "##6\n",
      "##7\n",
      "##ic\n",
      "##x\n",
      "##v\n",
      "##te\n",
      "##8\n",
      "##5\n",
      "##ne\n",
      "##ie\n",
      "##ton\n",
      "##9\n",
      "##0\n",
      "##ta\n",
      "##th\n",
      "##la\n",
      "##ness\n",
      "##ch\n",
      "##um\n",
      "##da\n",
      "##ry\n",
      "##w\n",
      "##ma\n",
      "##rs\n",
      "##el\n",
      "##re\n",
      "##os\n",
      "##ar\n",
      "##ka\n",
      "##ist\n",
      "##ian\n",
      "##or\n",
      "##ism\n",
      "##ling\n",
      "##ity\n",
      "##as\n",
      "##ley\n",
      "##ted\n",
      "##ng\n",
      "##ville\n",
      "##able\n",
      "##ri\n",
      "##ies\n",
      "##land\n",
      "##ur\n",
      "##ya\n",
      "##ine\n",
      "##de\n",
      "##ki\n",
      "##ts\n",
      "##ro\n",
      "##less\n",
      "##ey\n",
      "##ion\n",
      "##ha\n",
      "##am\n",
      "##ter\n"
     ]
    }
   ],
   "source": [
    "grep '^##'< BERT-vocab.txt | head -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these are recognizable as English suffixes (-ed, -ing, -ly, etc).  Along with these we have a lot of single character \"subwords\".  Let's stipulate that none of these are what we had in mind for 'words'.  Not to say they aren't useful or have meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5828\n"
     ]
    }
   ],
   "source": [
    "grep '^##' < BERT-vocab.txt | wc -l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we just lost nearly another 6k entries. Starting to sound like maybe BERT's vocab isn't all its cracked up to be.  More like 22k.\n",
    "\n",
    "Let's take a look at what's left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "of\n",
      "and\n",
      "in\n",
      "to\n",
      "was\n",
      "he\n",
      "is\n",
      "as\n",
      "for\n",
      "on\n",
      "with\n",
      "that\n",
      "it\n",
      "his\n",
      "by\n",
      "at\n",
      "from\n",
      "her\n",
      "she\n",
      "you\n",
      "had\n",
      "an\n",
      "were\n",
      "but\n",
      "be\n",
      "this\n",
      "are\n",
      "not\n",
      "my\n",
      "they\n",
      "one\n",
      "which\n",
      "or\n",
      "have\n",
      "him\n",
      "me\n",
      "first\n",
      "all\n",
      "also\n",
      "their\n",
      "has\n",
      "up\n",
      "who\n",
      "out\n",
      "been\n",
      "when\n",
      "after\n",
      "there\n",
      "into\n",
      "new\n",
      "two\n",
      "its\n",
      "time\n",
      "would\n",
      "no\n",
      "what\n",
      "about\n",
      "said\n",
      "we\n",
      "over\n",
      "then\n",
      "other\n",
      "so\n",
      "more\n",
      "can\n",
      "if\n",
      "like\n",
      "back\n",
      "them\n",
      "only\n",
      "some\n",
      "could\n",
      "where\n",
      "just\n",
      "during\n",
      "before\n",
      "do\n",
      "made\n",
      "school\n",
      "through\n",
      "than\n",
      "now\n",
      "years\n",
      "most\n",
      "world\n",
      "may\n",
      "between\n",
      "down\n",
      "well\n",
      "three\n",
      "year\n",
      "while\n",
      "will\n",
      "later\n",
      "city\n",
      "under\n",
      "around\n",
      "did\n",
      "such\n",
      "being\n",
      "used\n",
      "state\n",
      "people\n",
      "part\n",
      "know\n",
      "against\n",
      "your\n",
      "many\n",
      "second\n",
      "university\n",
      "both\n",
      "national\n",
      "these\n",
      "don\n",
      "known\n",
      "off\n",
      "way\n",
      "until\n",
      "re\n",
      "how\n",
      "even\n",
      "get\n",
      "head\n",
      "...\n",
      "didn\n",
      "team\n",
      "american\n",
      "because\n",
      "de\n",
      "born\n",
      "united\n",
      "film\n",
      "since\n",
      "still\n",
      "long\n",
      "work\n",
      "south\n",
      "us\n",
      "became\n",
      "any\n",
      "high\n",
      "again\n",
      "day\n",
      "family\n",
      "see\n",
      "right\n",
      "man\n",
      "eyes\n",
      "house\n",
      "season\n",
      "war\n",
      "states\n",
      "including\n",
      "took\n",
      "life\n",
      "north\n",
      "same\n",
      "each\n",
      "called\n",
      "name\n",
      "much\n",
      "place\n",
      "however\n",
      "go\n",
      "four\n",
      "group\n",
      "another\n",
      "found\n",
      "won\n",
      "area\n",
      "here\n",
      "going\n",
      "10\n",
      "away\n",
      "series\n",
      "left\n",
      "home\n",
      "music\n",
      "best\n",
      "make\n",
      "hand\n",
      "number\n",
      "company\n",
      "several\n",
      "never\n",
      "last\n",
      "john\n",
      "000\n",
      "very\n",
      "album\n",
      "take\n",
      "end\n",
      "good\n",
      "too\n",
      "following\n",
      "released\n",
      "game\n",
      "played\n",
      "little\n"
     ]
    }
   ],
   "source": [
    "grep -v '\\[' < BERT-vocab.txt | grep -v '^.$' | grep -v '^##' | head -200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although its not stated, this is obviously a frequency ordered list. \"the\" is always at the top.\n",
    "\n",
    "Let's just sort it alphanumerically to see what's in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "£1\n",
      "£10\n",
      "£100\n",
      "£2\n",
      "£3\n",
      "£5\n",
      "...\n",
      "00\n",
      "000\n",
      "001\n",
      "00pm\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "050\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "100\n",
      "1000\n",
      "100th\n",
      "101\n",
      "1016\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "1086\n",
      "109\n",
      "10th\n",
      "11\n",
      "110\n",
      "1100\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "11th\n",
      "12\n",
      "120\n",
      "1200\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "12th\n",
      "13\n",
      "130\n",
      "1300\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "13th\n",
      "14\n",
      "140\n",
      "1400\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "14th\n",
      "15\n",
      "150\n",
      "1500\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "1540\n",
      "155\n",
      "1550\n",
      "156\n",
      "1560\n",
      "157\n",
      "1570\n",
      "158\n",
      "1580\n",
      "159\n",
      "15th\n",
      "16\n",
      "160\n",
      "1600\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1609\n",
      "161\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1618\n",
      "162\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1628\n",
      "1629\n",
      "163\n",
      "1630\n",
      "1632\n",
      "1634\n",
      "1635\n",
      "1638\n",
      "164\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1648\n",
      "1649\n",
      "165\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1658\n",
      "1659\n",
      "166\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "167\n",
      "1670\n",
      "1672\n",
      "1675\n",
      "1679\n",
      "168\n",
      "1680\n",
      "1682\n",
      "1683\n",
      "1685\n",
      "1688\n",
      "1689\n",
      "169\n",
      "1690\n",
      "1692\n",
      "1695\n",
      "1697\n",
      "1699\n",
      "16th\n",
      "17\n",
      "170\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "171\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n"
     ]
    }
   ],
   "source": [
    "grep -v '\\[' < BERT-vocab.txt | grep -v '^.$' | grep -v '^##'  | sort | head -200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm.  Numbers, lots of numbers, time expressions, etc.  Also not words.\n",
    "\n",
    "Let's just get the numbers that constitute the whole line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "egrep -o '[[:digit:]]+' < BERT-vocab.txt | head -200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2072    2072    8239\n"
     ]
    }
   ],
   "source": [
    "egrep -o '[0-9]+' < BERT-vocab.txt | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's 2000 entries that are just plain numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about a bit of morphology?  BERT should get credit for knowing \"look\". But it shouldn't get credit for knowing 4 words just because it knows all the inflected forms for this regular verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked\n",
      "look\n",
      "looking\n",
      "looks\n",
      "lookout\n"
     ]
    }
   ],
   "source": [
    "grep '^look' < BERT-vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
